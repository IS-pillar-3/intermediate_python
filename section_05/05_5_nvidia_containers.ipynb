{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <center>Intermediate Python and Software Enginnering</center>\n",
    "\n",
    "\n",
    "## <center>Section 05 - Part 05 - NVIDIA Containers for CUDA</center>\n",
    "\n",
    "\n",
    "### <center>Innovation Scholars Programme</center>\n",
    "### <center>King's College London, Medical Research Council and UKRI <center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "```sh\n",
    "$ docker run --gpus all nvidia/cuda nvidia-smi\n",
    "```\n",
    "```\n",
    "Tue Jun  2 11:42:20 2020\n",
    "+-----------------------------------------------------------------------------+\n",
    "| NVIDIA-SMI 418.87.01    Driver Version: 418.87.01    CUDA Version: 10.1     |\n",
    "|-------------------------------+----------------------+----------------------+\n",
    "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
    "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
    "|===============================+======================+======================|\n",
    "|   0  GeForce GTX 980     Off  | 00000000:01:00.0  On |                  N/A |\n",
    "|  0%   38C    P8    20W / 195W |     85MiB /  4036MiB |      0%      Default |\n",
    "+-------------------------------+----------------------+----------------------+\n",
    "|   1  TITAN X (Pascal)    Off  | 00000000:02:00.0 Off |                  N/A |\n",
    "| 23%   30C    P8     9W / 250W |     12MiB / 12196MiB |      0%      Default |\n",
    "+-------------------------------+----------------------+----------------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Docker with API version 1.40 supports GPUs by default, versions earlier required complex setup to work with Nvidia containers\n",
    "* `--gpus all` states the container should use all GPUs available, these can be specified individually instead, eg. select GPU 1: `--gpus \\\"device=1\\\"`\n",
    "* Images are provided for various versions of CUDA cuDNN, and base systems such as Ubuntu\n",
    "* Let us create a simple Pytorch image to test this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "```dockerfile\n",
    "FROM nvidia/cuda:10.1-cudnn7-runtime-ubuntu18.04\n",
    "\n",
    "RUN apt-get update --fix-missing\n",
    "RUN apt-get install python3 python3-pip -y\n",
    "RUN pip3 install torch==1.5.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "\n",
    "CMD [\"python3\", \"-c\", \"import torch; print(torch.__version__, torch.cuda.device_count())\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* This will take a while to download Pytorch:\n",
    "\n",
    "```sh\n",
    "$ docker build -t hello-gpu .\n",
    "```\n",
    "\n",
    "* Then run:\n",
    "\n",
    "```sh\n",
    "$ docker run --gpus all -ti --rm hello-gpu\n",
    "1.5.0+cu101 2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* This installs Python 3 (explicitly as package `python3` because of Ubuntu's naming scheme) and Pytorch\n",
    "* Installing other libraries obviously done through `pip3`\n",
    "* Alternative is to download `miniconda` in the image and install things with `conda`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Resources other than the GPU can be controlled through `docker run`:\n",
    "  * `-m` sets memory limit, eg. `-m 1G` for 1GB of memory max\n",
    "  * `--memory-swap` sets swap file usage, -1 for no swap\n",
    "  * `--cpus` sets CPU resource allocation, eg. `--cpus=\\\"1.5\\\"` allocates 1 CPU and 0.5 of another\n",
    "  * `--cpuset-cpus` sets which CPU sets a container can use, eg. `--cpuset-cpus=\\\"1-3\\\"`\n",
    "  * `--cpu-shares` sets the share of CPU resources out of 1024, used to balance allocation between containers\n",
    "* Further flags permit more fine-grained control"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
