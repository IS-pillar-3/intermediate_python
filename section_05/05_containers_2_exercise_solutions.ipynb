{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <center>Intermediate Python and Software Enginnering</center>\n",
    "\n",
    "\n",
    "## <center>Section 05 - Containers 2 - Exercise Solutions</center>\n",
    "\n",
    "\n",
    "### <center>Innovation Scholars Programme</center>\n",
    "### <center>King's College London, Medical Research Council and UKRI <center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02 Exercises\n",
    "\n",
    "This exercise will cover GPU computation with docker images.\n",
    "\n",
    "### Installation\n",
    "\n",
    "We need to install the Nvidia Container Toolkit, instructions are [here](https://github.com/NVIDIA/nvidia-docker).\n",
    "\n",
    "*NB: At some point in the past on Ubuntu 16.04 I had to follow [these instructions](https://cnvrg.io/how-to-setup-docker-and-nvidia-docker-2-0-on-ubuntu-18-04) for getting the correct version of Docker and the Nvidia runtime. This was with a version of Docker before 19.03, so check your version with `docker version` to make sure you have at least that version otherwise those instructions might be necessary.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1:\n",
    "\n",
    "We'll write a simple Pytorch program to produce some information about the environment they're being run under to see what a CUDA-aware container looks like.\n",
    "\n",
    "**Step 1:** Create a directory called `exercise02` and copy the following into it as `pytorch_test.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p exercise02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing exercise02/pytorch_test.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile exercise02/pytorch_test.py\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import timeit\n",
    "\n",
    "print(f'Host name: {os.environ[\"HOSTNAME\"]}')\n",
    "print(f'Pytorch version: {torch.__version__}')\n",
    "\n",
    "for d in range(torch.cuda.device_count()):\n",
    "    p = torch.cuda.get_device_properties(d)\n",
    "    print(f\"Device {d} is {p.name} with {p.total_memory/2**30}GiB of memory\")\n",
    "    \n",
    "test=torch.rand(10,1,64,64)\n",
    "conv=torch.nn.Conv2d(1,1,3,1,1)\n",
    "\n",
    "result=timeit.timeit(\"conv(test)\",number=1000,globals=locals())\n",
    "print(f'CPU time: {result}')\n",
    "\n",
    "test=test.to('cuda:0')\n",
    "conv=conv.to('cuda:0')\n",
    "\n",
    "result=timeit.timeit(\"conv(test)\",number=1000,globals=locals())\n",
    "print(f'GPU time: {result}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2:** Now define the Dockerfile based off one of the CUDA [images of your choice](https://hub.docker.com/r/nvidia/cuda/tags). You'll need to install Pytorch so refer to the notes for how to do that. The Dockerfile should copy over the test file we just created and run it as the command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting exercise02/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile exercise02/Dockerfile\n",
    "\n",
    "FROM nvidia/cuda:10.1-cudnn7-runtime-ubuntu18.04\n",
    "\n",
    "RUN apt update --fix-missing\n",
    "RUN apt install -y python3-pip\n",
    "\n",
    "RUN pip3 install torch==1.5.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "    \n",
    "COPY pytorch_test.py /\n",
    "\n",
    "RUN adduser dockeruser --shell /bin/bash\n",
    "USER dockeruser\n",
    "\n",
    "CMD [\"python3\", \"pytorch_test.py\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3:** build the image tagging it as `pytorch-test`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  3.584kB\n",
      "Step 1/8 : FROM nvidia/cuda:10.1-cudnn7-runtime-ubuntu18.04\n",
      " ---> e135227729c4\n",
      "Step 2/8 : RUN apt update --fix-missing\n",
      " ---> Using cache\n",
      " ---> d25e1520b14e\n",
      "Step 3/8 : RUN apt install -y python3-pip\n",
      " ---> Using cache\n",
      " ---> 8cf891a12497\n",
      "Step 4/8 : RUN pip3 install torch==1.5.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
      " ---> Using cache\n",
      " ---> 3a652ee32b8f\n",
      "Step 5/8 : COPY pytorch_test.py /\n",
      " ---> Using cache\n",
      " ---> 92a2710c7629\n",
      "Step 6/8 : RUN adduser dockeruser --shell /bin/bash\n",
      " ---> Running in babe80f0451e\n",
      "Adding user `dockeruser' ...\n",
      "Adding new group `dockeruser' (1000) ...\n",
      "Adding new user `dockeruser' (1000) with group `dockeruser' ...\n",
      "Creating home directory `/home/dockeruser' ...\n",
      "Copying files from `/etc/skel' ...\n",
      "\u001b[91mEnter new UNIX password: Retype new UNIX password: passwd: Authentication token manipulation error\n",
      "passwd: password unchanged\n",
      "\u001b[0m\u001b[91mUse of uninitialized value $answer in chop at /usr/sbin/adduser line 591.\n",
      "Use of uninitialized value $answer in pattern match (m//) at /usr/sbin/adduser line 592.\n",
      "\u001b[0mTry again? [y/N] Changing the user information for dockeruser\n",
      "Enter the new value, or press ENTER for the default\n",
      "\tFull Name []: \tRoom Number []: \tWork Phone []: \tHome Phone []: \tOther []: \u001b[91mUse of uninitialized value $answer in chop at /usr/sbin/adduser line 621.\n",
      "Use of uninitialized value $answer in pattern match (m//) at /usr/sbin/adduser line 622.\n",
      "\u001b[0mIs the information correct? [Y/n] Removing intermediate container babe80f0451e\n",
      " ---> 42f526b3a8d4\n",
      "Step 7/8 : USER dockeruser\n",
      " ---> Running in 3a0d2f0f6d61\n",
      "Removing intermediate container 3a0d2f0f6d61\n",
      " ---> aa63c6f50393\n",
      "Step 8/8 : CMD [\"python3\", \"pytorch_test.py\"]\n",
      " ---> Running in a2f7279ccb70\n",
      "Removing intermediate container a2f7279ccb70\n",
      " ---> 134b0bf31029\n",
      "Successfully built 134b0bf31029\n",
      "Successfully tagged pytorch-test:latest\n"
     ]
    }
   ],
   "source": [
    "!docker build exercise02 -t pytorch-test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4:** Run the image with and without the GPU flag (refer to the notes) to see how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Host name: d7d074a74c25\r\n",
      "Pytorch version: 1.5.0+cu101\r\n",
      "Device 0 is TITAN X (Pascal) with 11.91021728515625GiB of memory\r\n",
      "Device 1 is GeForce GTX 980 with 3.9422607421875GiB of memory\r\n",
      "CPU time: 0.33359767915681005\r\n",
      "GPU time: 0.07265682704746723\r\n"
     ]
    }
   ],
   "source": [
    "!docker run --gpus all --rm -u $(id -u):$(id -g) pytorch-test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5:** So far we've been using `CMD` to define the command to run. A related Dockerfile command is `ENTRYPOINT` which provides a command to run but is not replaced when arguments are used with `docker run`. With `CMD` any extra arguments will replace what was provided, but with `ENTRYPOINT` they are appended to the end of the command to act as additional arguments. Both can be used at once, `ENTRYPOINT` defining the command and `CMD` giving default arguments.\n",
    "\n",
    "Let's modify our Dockerfile to run the given script as the default behaviour but allow any other arguments to be used as well. We can define a general purpose container this way which can used to execute any script we provided through a volume directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting exercise02/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile exercise02/Dockerfile\n",
    "\n",
    "FROM nvidia/cuda:10.1-cudnn7-runtime-ubuntu18.04\n",
    "\n",
    "RUN apt update --fix-missing\n",
    "RUN apt install -y python3-pip\n",
    "\n",
    "RUN pip3 install torch==1.5.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "    \n",
    "COPY pytorch_test.py /\n",
    "\n",
    "RUN adduser dockeruser --shell /bin/bash\n",
    "USER dockeruser\n",
    "\n",
    "ENTRYPOINT [\"python3\"]\n",
    "CMD [\"pytorch_test.py\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2:\n",
    "Make an account on Docker Hub and upload your new image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3:\n",
    "\n",
    "Docker Swarm allows us to run instances of Docker images on worker nodes commanded from a manager node. Typically these nodes would be separate server hosts and any incoming requests are distributed amongst them to balance load. Large scale web services are architected this way since single servers wouldn't be able to respond to the amount of traffice they'd receive. \n",
    "\n",
    "We don't have spare server racks kicking around to demonstrate this on but we can see what it looks like with one manager node at least.\n",
    "\n",
    "**Step 1:** Create a directory called `hello_swarm` and copy the following into it as `hello_host.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p hello_swarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting hello_swarm/hello_host.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile hello_swarm/hello_host.py\n",
    "\n",
    "import os\n",
    "from flask import Flask\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def hello_world():\n",
    "    return f\"Hello from host {os.environ['HOSTNAME']}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2:** Define a Dockerfile like those used for Flask applications already but with the `FLASK_APP` value set to `hello_host.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile hello_swarm/Dockerfile\n",
    "\n",
    "from python:3.7\n",
    "ENV FLASK_APP hello_host.py\n",
    "COPY hello_host.py /\n",
    "RUN pip install flask\n",
    "\n",
    "EXPOSE 5000\n",
    "\n",
    "CMD [\"flask\",\"run\",\"--host=0.0.0.0\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3:**\n",
    "Build the image tagging it as `hello-swarm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  3.072kB\n",
      "Step 1/6 : from python\n",
      " ---> 659f826fabf4\n",
      "Step 2/6 : ENV FLASK_APP hello_host.py\n",
      " ---> Running in f0a9e1742efc\n",
      "Removing intermediate container f0a9e1742efc\n",
      " ---> 37a8592160d9\n",
      "Step 3/6 : COPY hello_host.py /\n",
      " ---> ca856cd544cd\n",
      "Step 4/6 : RUN pip install flask\n",
      " ---> Running in de82183df348\n",
      "Collecting flask\n",
      "  Downloading Flask-1.1.2-py2.py3-none-any.whl (94 kB)\n",
      "Collecting click>=5.1\n",
      "  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "Collecting itsdangerous>=0.24\n",
      "  Downloading itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting Jinja2>=2.10.1\n",
      "  Downloading Jinja2-2.11.2-py2.py3-none-any.whl (125 kB)\n",
      "Collecting Werkzeug>=0.15\n",
      "  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "Collecting MarkupSafe>=0.23\n",
      "  Downloading MarkupSafe-1.1.1-cp38-cp38-manylinux1_x86_64.whl (32 kB)\n",
      "Installing collected packages: click, itsdangerous, MarkupSafe, Jinja2, Werkzeug, flask\n",
      "Successfully installed Jinja2-2.11.2 MarkupSafe-1.1.1 Werkzeug-1.0.1 click-7.1.2 flask-1.1.2 itsdangerous-1.1.0\n",
      "Removing intermediate container de82183df348\n",
      " ---> 03b94044218c\n",
      "Step 5/6 : EXPOSE 5000\n",
      " ---> Running in aac148f6fd56\n",
      "Removing intermediate container aac148f6fd56\n",
      " ---> c1190389dab3\n",
      "Step 6/6 : CMD [\"flask\",\"run\",\"--host=0.0.0.0\"]\n",
      " ---> Running in f5f9e50d2b31\n",
      "Removing intermediate container f5f9e50d2b31\n",
      " ---> 858bb8b73e40\n",
      "Successfully built 858bb8b73e40\n",
      "Successfully tagged hello-swarm:latest\n"
     ]
    }
   ],
   "source": [
    "!docker build hello_swarm -t hello-swarm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4:**\n",
    "Initialize Swarm with with the command `docker swarm init`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Swarm initialized: current node (st8r37wmqe95npg4robbwmktq) is now a manager.\r\n",
      "\r\n",
      "To add a worker to this swarm, run the following command:\r\n",
      "\r\n",
      "    docker swarm join --token SWMTKN-1-0gwlcfgnztev9we5mmkp0ujp9llm0womddzosb45b0drmj9152-1j0zipzqtq3mkyrsd9kwwmdlq 10.246.179.34:2377\r\n",
      "\r\n",
      "To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!docker swarm init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5:**\n",
    "The command for join it gives you could be run on other hosts to add them as worker nodes, we could create a VM with Virtualbox or use Docker-machine to do this for us, but for now we can run a service with multiple instances on your single node.\n",
    "\n",
    "We want to create a service, specifying our image as the one to use (or multiple images with Docker Compose) with other flags to specify name, number of replicas to use (ie. how many copies of the container to run), and port routing. Run the following:\n",
    "\n",
    "```sh\n",
    "docker service create --name hello_swarm --publish published=5000,target=5000 --replicas 2 hello_swarm\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image hello_swarm:latest could not be accessed on a registry to record\n",
      "its digest. Each node will access hello_swarm:latest independently,\n",
      "possibly leading to different nodes running different\n",
      "versions of the image.\n",
      "\n",
      "hw5tpukdg4anx9n44y4igr4ra\n",
      "\n",
      "\u001b[1Ball progress: 0 out of 2 tasks \n",
      "\u001b[1B   K\n",
      "\u001b[3Ball progress: 2 out of 2 tasks \u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[1A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[1A\u001b[2K\n",
      "\u001b[1Bfy: Service converged to verify that tasks are stable... \u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K"
     ]
    }
   ],
   "source": [
    "!docker service create --name hello_swarm --publish published=5000,target=5000 --replicas 2 hello_swarm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6:**\n",
    "We want to now query our running application through the IP address mentioned in the `docker swarm join` command suggested when you ran `docker swarm init`. This is the external interface IP address Swarm is listening to for incoming requests. You can open a browser and navigate to that IP and port 5000 or use `curl` if you can't access the machine directly. What you expect to see is the server responding with 2 different host names, one for each replica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello from host 9ecf76a3f789"
     ]
    }
   ],
   "source": [
    "!curl 10.246.179.34:5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello from host eab61d930c73"
     ]
    }
   ],
   "source": [
    "!curl 10.246.179.34:5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 7:** Inspect what services are running with `docker service ls`. Our `hello-swarm` service is running, we don't need it now so kill it with `docker service rm hello_swarm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                  NAME                MODE                REPLICAS            IMAGE                PORTS\r\n",
      "hw5tpukdg4an        hello_swarm         replicated          2/2                 hello_swarm:latest   *:5000->5000/tcp\r\n"
     ]
    }
   ],
   "source": [
    "!docker service ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello_swarm\r\n"
     ]
    }
   ],
   "source": [
    "!docker service rm hello_swarm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So if we have an application (ie. a web server running in a container serving pages and other media to clients), how do they get data, communicate with each other if necessary, communicate with databases and synchronize their contents, and otherwise behave like a single server? One way is with volumes which can be created through Docker so that containers can access and share file data. Other running services can be set to serve multiple workers, ie. having a container running the database multiple instance of a web server access. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
